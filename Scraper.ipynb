{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "751 sivu\n",
      "750 sivu\n",
      "749 sivu\n",
      "748 sivu\n",
      "747 sivu\n",
      "746 sivu\n",
      "745 sivu\n",
      "744 sivu\n",
      "743 sivu\n",
      "742 sivu\n",
      "741 sivu\n",
      "740 sivu\n",
      "739 sivu\n",
      "738 sivu\n",
      "737 sivu\n",
      "736 sivu\n",
      "735 sivu\n",
      "734 sivu\n",
      "733 sivu\n",
      "732 sivu\n",
      "731 sivu\n",
      "730 sivu\n",
      "729 sivu\n",
      "728 sivu\n",
      "727 sivu\n",
      "726 sivu\n",
      "725 sivu\n",
      "724 sivu\n",
      "723 sivu\n",
      "722 sivu\n",
      "721 sivu\n",
      "720 sivu\n",
      "719 sivu\n",
      "718 sivu\n",
      "717 sivu\n",
      "716 sivu\n",
      "715 sivu\n",
      "714 sivu\n",
      "713 sivu\n",
      "712 sivu\n",
      "711 sivu\n",
      "710 sivu\n",
      "709 sivu\n",
      "708 sivu\n",
      "707 sivu\n",
      "706 sivu\n",
      "705 sivu\n",
      "704 sivu\n",
      "703 sivu\n",
      "702 sivu\n",
      "100 autoa\n",
      "200 autoa\n",
      "300 autoa\n",
      "400 autoa\n",
      "500 autoa\n",
      "600 autoa\n",
      "700 autoa\n",
      "800 autoa\n",
      "900 autoa\n",
      "1000 autoa\n",
      "1100 autoa\n",
      "1200 autoa\n",
      "1300 autoa\n",
      "1400 autoa\n",
      "1500 autoa\n",
      "success\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "autot=[]\n",
    "ids=[]\n",
    "i=0\n",
    "WEBSITE = \"\"\n",
    "\n",
    "#You can decide how many cars you want to include to your research by changing range number. \n",
    "for x in range(751,701,-1):\n",
    "    print(x, 'sivu')\n",
    "    website=WEBSITE.format(x)    \n",
    "    response = requests.get(website)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    # Convert to string\n",
    "    pretty = soup.prettify()\n",
    "\n",
    "    # Write to external file\n",
    "    with open(\"output1.html\", \"w\", encoding='utf-8') as file:\n",
    "        file.write(pretty)\n",
    "\n",
    "    cars = soup.select('a')    # Soup object type\n",
    "    # Go through car makers in website \n",
    "\n",
    "    for idt in cars:\n",
    "        idt=str(idt.get('data-id'))\n",
    "        if idt == 'None':\n",
    "            pass\n",
    "        else:\n",
    "            ids.append(idt)\n",
    "            \n",
    "    #You can decide how many cars you want to include to your research by changing range number.\n",
    "for x in range(0,1500):\n",
    "        i+=1\n",
    "        time.sleep(0.1)\n",
    "        website=WEBSITE.format(ids[x])    \n",
    "        response = requests.get(website)\n",
    "        ids[x] = {}\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        pretty = soup.prettify()\n",
    "        try:\n",
    "            tables = soup.find_all('table', {'class':'data_table'})\n",
    "            #T채m채 ottaa nettiauto.comin taulukon ja raapii tiedot siit채 listaan.\n",
    "            bs=BeautifulSoup(response.content, \"lxml\")\n",
    "            table_body=bs.find('table', {'class':'data_table'})\n",
    "            rows = table_body.find_all('tr')\n",
    "\n",
    "            for row in rows:\n",
    "                cols=row.find_all('td')\n",
    "                cols = [ele.text.strip() for ele in cols]\n",
    "                cols = [ele for ele in cols if ele]  \n",
    "\n",
    "                #Adds data from the table to dict\n",
    "                try:\n",
    "                    ids[x][cols[0]]=cols[1]             \n",
    "                except:\n",
    "                    pass           \n",
    "                try:\n",
    "                    ids[x][cols[2]]=cols[3]               \n",
    "                except:\n",
    "                    pass\n",
    "        except:\n",
    "            pass\n",
    "        cars = soup.findAll(\"div\", {\"class\": \"mid_border br_blr5_border\"})\n",
    "        for maker in cars:\n",
    "            ids[x][\"Valmistaja\"]=maker.get('data-make')\n",
    "            ids[x][\"Malli\"]=maker.get('data-model')\n",
    "            ids[x][\"Auton tyyppi\"]=maker.get('data-vtype')\n",
    "            ids[x][\"Myyj채\"]=maker.get('data-postedby')\n",
    "            ids[x][\"Hinta\"]=maker.get('data-price')\n",
    "            ids[x][\"Vuosimalli\"]=maker.get('data-year')\n",
    "            ids[x][\"Mittarilukema\"]=maker.get('data-mileage')\n",
    "            id=ids[x][\"Id\"]=maker.get('data-id')\n",
    "        autot.append(ids[x])\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            print(i, 'autoa')\n",
    "    \n",
    "\n",
    "    \n",
    "    #This creates dataframe and saves it  \n",
    "df = pd.DataFrame(autot)\n",
    "df.to_csv('Cardata7.csv', encoding='utf8')\n",
    "print(\"success\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
